\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{dcolumn} % Booktabs column spacing
\usepackage{threeparttable} % Align column caption, table, and notes
\usepackage{adjustbox} % Shrink boxes
\usepackage{float}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Heart Disease Prediction}

\author{\IEEEauthorblockN{Xavier Santos}
    \IEEEauthorblockA{\textit{Departamento de Eletrónica, Telecomunicações e Informática} \\
        \textit{Universidade de Aveiro}\\
        Aveiro, Portugal \\
        xavier@ua.pt
    }
}

\maketitle

\begin{abstract}
    This project aims to find the most efficient model to predict the presence of a heart disease on a patient based on 14 preconditions and exam results from a single hospital and then test the trained models against data from hospitals in different hospitals and countries.
\end{abstract}

\begin{IEEEkeywords}
    machine learning, dataset, heart disease, prediction, logistic regression, naive Bayes, k nearest neighbors, decision tree, random forest
\end{IEEEkeywords}

\section{Introduction}
For this study, it was analyzed the data form the UCI Machine Learning Repository\cite{mlr} regarding patient data used to ascertain the presence of a heart disease. In order to predict said disease five models of prediction were used: Logistic Regression, Naive Bayes, K Nearest Neighbors, Decision Tree and Random Forest.

\section{Dataset}
The dataset used for training contains the data of 303 patients from a hospital in Cleveland\cite{va} described by 14 attributes each; 5 of which were numerical values while the other 9 represented categories. The "goal" field was given by a binary value representing the presence or absence of heart disease in the patient. There were other 3 other datasets from Hungary\cite{hun}, Switzerland\cite{swz1,swz2} and Long Beach\cite{va} in which the models obtained from the first set were tested after the training. Most of these datasets, however, had many missing values.\\
The features used are age, sex, chest pain type, resting blood pressure, cholesterol, fasting blood sugar, resting electrocardiogram, maximum heart rate, exercise induced angina, ST depression, ST slope, number of major vessels and Thallium stress test results. An example of a portion the data is show in Table \ref{data_head}.

\begin{table}[htbp]
    \caption{Data head}
    \begin{center}
        \resizebox{\columnwidth}{!}{%
            \input{tables/data_head.tex}
        }%
        \label{data_head}
    \end{center}
\end{table}

\section{Data analysis}

There is some information that can be gathered from a preliminary analysis of the data. Like the distribution of diseased patients by each category (Figure \ref{hist_cat}) or the numeric value distribution of all patients (Figure \ref{hist_num}).

\begin{figure}[htpb]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=1\linewidth]{images/view_categorical.pdf}
        \caption{Categorical values}
        \label{hist_cat}
    \end{subfigure}      
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=1\linewidth]{images/view_numerical.pdf}
        \caption{Numerical values}
        \label{hist_num}
    \end{subfigure}
    \label{hist}
    \caption[Histograms]{Histogram of the features}
\end{figure}

\begin{table}[htbp]
    \caption{Data correlation}
    \begin{center}
        \input{tables/data_correlation.tex}
        \label{data_corr}
    \end{center}
\end{table}

\newpage

But what interests us the most is the relation between this attributes (features) and a case of heart disease(goal).
\\It was verified that some features have more impact on the patient's diagnosis than others. For instance, if a patient has or not exercise induced angina is a much stronger indicator of a heart disease than his number of major vessels or fasting blood sugar value as it can be seen in Table \ref{data_corr} and Figures \ref{corr_heatmap} and \ref{corr_scatter}.

\begin{figure}[htpb]
    \centerline{\includegraphics[width=0.7\linewidth]{images/correlation_heatmap.pdf}}
    \caption{Heat map of the correlation between the features and the diagnosis}
    \label{corr_heatmap}
\end{figure}

\begin{figure}[htpb]
    \centerline{\includegraphics[width=\linewidth]{images/correlation_scatter.pdf}}
    \caption{Scatter plots of the correlation between the features and the diagnosis}
    \label{corr_scatter}
\end{figure}

\section{Data Preprocessing}
The data is provided by the UCI Machine Learning Repository\cite{mlr} in the format of a CSV file with the classifiers encoded into integers. The target is transformed from 5 different values for different heart disease to a binary value of diseased or not diseased.\\
Before training the models the data had to be prepared by filling the missing values on some of the features. This was achieved by giving the mean value for that feature if it was a numeric value or the most common value if it was categorical.\\
The data was then shuffled and split in two sets: one for training and another one for testing and cross-validation with the distribution of 80\% and 20\% respectively.

\section{Model training and tuning}

\subsection{Logistic Regression}
The logistic regression model uses a "liblinear" solver as it provides better results with smaller datasets and the goal we are taking in consideration is binary (disease / no disease).

\begin{figure}[H]
    \centerline{\includegraphics[width=0.9\linewidth]{images/LogisticRegression_lc.pdf}}
    \caption{Logistic Regression Learning Curve}
    \label{lr_lc}
\end{figure}

\noindent
\input{logs/log_reg.tex}

\begin{figure}[H]
    \centerline{\includegraphics[width=0.8\linewidth]{images/log_reg_cm.pdf}}
    \caption{Logistic Regression Confusion Matrix}
    \label{lr_cm}
\end{figure}

\subsection{Naive Bayes}
Both the Gaussian and Bernoulli variants of the model were tested, but Bernoulli gave the best results. The Bernoulli method deals in binary inputs and transforms the rest of the data to binary-valued feature vectors. It is based on the formula:
\\[\baselineskip]
\centerline{$P(x_i \mid y) = P(i \mid y) x_i + (1 - P(i \mid y)) (1 - x_i)$}
\\[\baselineskip]
which means it penalizes the non-occurrence of a feature.

\begin{figure}[H]
    \centerline{\includegraphics[width=0.9\linewidth]{images/BernoulliNB_lc.pdf}}
    \caption{Naive Bayes Learning Curve}
    \label{nb_lc}
\end{figure}

\noindent
\input{logs/naive_bayes.tex}

\begin{figure}[H]
    \centerline{\includegraphics[width=0.8\linewidth]{images/naive_bayes_cm.pdf}}
    \caption{Naive Bayes Confusion Matrix}
    \label{nb_cm}
\end{figure}

\subsection{K Nearest Neighbors}
The optimal choice of the value of \textit{K} is highly data-dependent: in general a larger suppresses the effects of noise, but makes the classification boundaries less distinct. This model implements learning based on the \textit{K} nearest neighbors of each query point, where \textit{K} was selected from testing multiple candidates of which \textit{K}=3 gave the best results for the test set.

\begin{figure}[H]
    \centerline{\includegraphics[width=0.9\linewidth]{images/KNeighborsClassifier_lc.pdf}}
    \caption{K Nearest Neighbors Learning Curve}
    \label{knn_lc}
\end{figure}

\noindent
\input{logs/k_nearest_neighbors.tex}

\begin{figure}[H]
    \centerline{\includegraphics[width=0.8\linewidth]{images/k_nearest_neighbors_cm.pdf}}
    \caption{K Nearest Neighbors Confusion Matrix}
    \label{knn_cm}
\end{figure}

\subsection{Decision Tree}
This model predicts the value of a target variable using simple if-then-else rules inferred from the data features. This decisions can be made on different levels (depth) until reaching the target goal.
\\For the selection of the maximum depth of the decision tree classifier were tested the values from 1 to 10 and the chosen the one which gave best results for the test subset.

\begin{figure}[H]
    \centerline{\includegraphics[width=0.9\linewidth]{images/DecisionTreeClassifier_lc.pdf}}
    \caption{Decision Tree Learning Curve}
    \label{dt_lc}
\end{figure}

\noindent
\input{logs/decision_tree.tex}

\begin{figure}[H]
    \centerline{\includegraphics[width=0.8\linewidth]{images/decision_tree_cm.pdf}}
    \caption{Decision Tree Confusion Matrix}
    \label{dt_cm}
\end{figure}

\subsection{Random Forest}

A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The optimal value between processing time and accuracy is 100 trees and the depth of each tree was tested for 10 values, being the depth of 1 the one that provided the best results.

\begin{figure}[H]
    \centerline{\includegraphics[width=0.9\linewidth]{images/RandomForestClassifier_lc.pdf}}
    \caption{Random Forest Learning Curve}
    \label{rf_lc}
\end{figure}

\noindent
\input{logs/random_forest.tex}

\begin{figure}[H]
    \centerline{\includegraphics[width=0.8\linewidth]{images/random_forest_cm.pdf}}
    \caption{Random Forest Confusion Matrix}
    \label{rf_cm}
\end{figure}

\section{Results}

Here we can see the comparison between the models for both the original dataset and some different ones from other hospitals.

\begin{table}[H]
    \caption{Results for the test section of the original data}
    \begin{center}
        \input{tables/original_test_summary.tex}
        \label{ori_res}
    \end{center}
\end{table}

In Table \ref{ori_res} are the results taken from the evaluation of 20\% of the data, which was left out from the original dataset for these tests. We can see that Random Forest and Logistic Regression gave us the best results.

\begin{table}[H]
    \caption{Results for the V.A. Medical Center's data}
    \begin{center}
        \input{tables/va_summary.tex}
        \label{va_res}
    \end{center}
\end{table}

In another hospital from the USA\cite{va}, whose results are shown in Table \ref{va_res}, we have some general decrease on accuracy, but the Naive Bayes model kept a relatively constant value. K Nearest Neighbors still gave the worst prediction and had a 10\% drop on accuracy.

\begin{table}[H]
    \caption{Results for the Swiss data}
    \begin{center}
        \input{tables/switzerland_summary.tex}
        \label{sw_res}
    \end{center}
\end{table}

Taking the data gathered by 2 hospitals in Switzerland\cite{swz1,swz2}, we see in Table \ref{sw_res} that K Nearest Neighbors predicts most of the cases wrong while Naive Bays keeps consistent and Decision Tree performs very well in this scenario.

\begin{table}[H]
    \caption{Results for the Hungarian data}
    \begin{center}
        \input{tables/hungary_summary.tex}
        \label{hun_res}
    \end{center}
\end{table}

The results taken from the data gathered by the Hungarian hospital\cite{hun} and displayed in Table \ref{hun_res} show that the Naive Bayes model keeps proving the most reliable method and the K Nearest Neighbors is the worse model tested in this conditions.

\section{Conclusion}

Given the results, we can conclude that the model that gave the overall best results was the Bernoulli Naive Bayes followed be the Decision Tree model. The Bernoulli Naive Bayes gave us good results to fit this specific dataset and it is light and simple to implement so it seems to be the best choice.
\\Random Forest also behaved well in most cases, but it is very demanding to process and the most time consuming of all the models tested.
\\The K Nearest Neighbors model was completely unusable in this dataset as it gave some worst than random predictions for some of the tests.
\\The dataset used for training was relatively small so most of the models didn't have enough data to converge and provide us with a reliable prediction and the datasets tested the models with were missing many of its attributes, so some of the results may be misleading.

\begin{thebibliography}{00}
    \bibitem{hun} Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
    \bibitem{swz1} University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
    \bibitem{swz2} University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
    \bibitem{va} V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:Robert Detrano, M.D., Ph.D.
    \bibitem{mlr} Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.
\end{thebibliography}

\end{document}
