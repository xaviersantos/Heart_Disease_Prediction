Decision Tree

max_depth = 1
Train accuracy: 76.86%
Test accuracy: 72.13%

predictions= [0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0
 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0]

Number of mislabeled points out of a total 61 points : 17
The accuracy score achieved is: 72.13 %
Confusion Matrix: 
[[26  9]
 [ 8 18]]

Classification report on full data set:
              precision    recall  f1-score   support

           0       0.76      0.74      0.75        35
           1       0.67      0.69      0.68        26

    accuracy                           0.72        61
   macro avg       0.72      0.72      0.72        61
weighted avg       0.72      0.72      0.72        61

False Negative Rate: 30.76923076923077
False Positive Rate: 25.714285714285715
------------------------------------------------------------------------------------------

Seek optimal 'max_depth' parameter:

max_depth = 2
Train accuracy: 76.86%
Test accuracy: 72.13%

predictions= [0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0
 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0]

Number of mislabeled points out of a total 61 points : 17
The accuracy score achieved is: 72.13 %
Confusion Matrix: 
[[26  9]
 [ 8 18]]

Classification report on full data set:
              precision    recall  f1-score   support

           0       0.76      0.74      0.75        35
           1       0.67      0.69      0.68        26

    accuracy                           0.72        61
   macro avg       0.72      0.72      0.72        61
weighted avg       0.72      0.72      0.72        61

False Negative Rate: 30.76923076923077
False Positive Rate: 25.714285714285715
------------------------------------------------------------------------------------------

max_depth = 3
Train accuracy: 85.12%
Test accuracy: 81.97%

predictions= [0 1 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0
 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0]

Number of mislabeled points out of a total 61 points : 11
The accuracy score achieved is: 81.97 %
Confusion Matrix: 
[[31  4]
 [ 7 19]]

Classification report on full data set:
              precision    recall  f1-score   support

           0       0.82      0.89      0.85        35
           1       0.83      0.73      0.78        26

    accuracy                           0.82        61
   macro avg       0.82      0.81      0.81        61
weighted avg       0.82      0.82      0.82        61

False Negative Rate: 26.923076923076923
False Positive Rate: 11.428571428571429
------------------------------------------------------------------------------------------

max_depth = 4
Train accuracy: 88.84%
Test accuracy: 77.05%

predictions= [0 0 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0
 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0]

Number of mislabeled points out of a total 61 points : 14
The accuracy score achieved is: 77.05 %
Confusion Matrix: 
[[29  6]
 [ 8 18]]

Classification report on full data set:
              precision    recall  f1-score   support

           0       0.78      0.83      0.81        35
           1       0.75      0.69      0.72        26

    accuracy                           0.77        61
   macro avg       0.77      0.76      0.76        61
weighted avg       0.77      0.77      0.77        61

False Negative Rate: 30.76923076923077
False Positive Rate: 17.142857142857142
------------------------------------------------------------------------------------------

max_depth = 5
Train accuracy: 93.39%
Test accuracy: 73.77%

predictions= [0 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0
 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0]

Number of mislabeled points out of a total 61 points : 16
The accuracy score achieved is: 73.77 %
Confusion Matrix: 
[[27  8]
 [ 8 18]]

Classification report on full data set:
              precision    recall  f1-score   support

           0       0.77      0.77      0.77        35
           1       0.69      0.69      0.69        26

    accuracy                           0.74        61
   macro avg       0.73      0.73      0.73        61
weighted avg       0.74      0.74      0.74        61

False Negative Rate: 30.76923076923077
False Positive Rate: 22.857142857142858
------------------------------------------------------------------------------------------

max_depth = 6
Train accuracy: 97.52%
Test accuracy: 72.13%

predictions= [0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0
 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0]

Number of mislabeled points out of a total 61 points : 17
The accuracy score achieved is: 72.13 %
Confusion Matrix: 
[[27  8]
 [ 9 17]]

Classification report on full data set:
              precision    recall  f1-score   support

           0       0.75      0.77      0.76        35
           1       0.68      0.65      0.67        26

    accuracy                           0.72        61
   macro avg       0.72      0.71      0.71        61
weighted avg       0.72      0.72      0.72        61

False Negative Rate: 34.61538461538461
False Positive Rate: 22.857142857142858
------------------------------------------------------------------------------------------

max_depth = 7
Train accuracy: 99.17%
Test accuracy: 73.77%

predictions= [0 1 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0
 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0]

Number of mislabeled points out of a total 61 points : 16
The accuracy score achieved is: 73.77 %
Confusion Matrix: 
[[28  7]
 [ 9 17]]

Classification report on full data set:
              precision    recall  f1-score   support

           0       0.76      0.80      0.78        35
           1       0.71      0.65      0.68        26

    accuracy                           0.74        61
   macro avg       0.73      0.73      0.73        61
weighted avg       0.74      0.74      0.74        61

False Negative Rate: 34.61538461538461
False Positive Rate: 20.0
------------------------------------------------------------------------------------------

max_depth = 8
Train accuracy: 100.00%
Test accuracy: 75.41%

predictions= [0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0
 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0]

Number of mislabeled points out of a total 61 points : 15
The accuracy score achieved is: 75.41 %
Confusion Matrix: 
[[27  8]
 [ 7 19]]

Classification report on full data set:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78        35
           1       0.70      0.73      0.72        26

    accuracy                           0.75        61
   macro avg       0.75      0.75      0.75        61
weighted avg       0.76      0.75      0.75        61

False Negative Rate: 26.923076923076923
False Positive Rate: 22.857142857142858
------------------------------------------------------------------------------------------

max_depth = 9
Train accuracy: 100.00%
Test accuracy: 75.41%

predictions= [0 1 0 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1 0 0
 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0]

Number of mislabeled points out of a total 61 points : 15
The accuracy score achieved is: 75.41 %
Confusion Matrix: 
[[27  8]
 [ 7 19]]

Classification report on full data set:
              precision    recall  f1-score   support

           0       0.79      0.77      0.78        35
           1       0.70      0.73      0.72        26

    accuracy                           0.75        61
   macro avg       0.75      0.75      0.75        61
weighted avg       0.76      0.75      0.75        61

False Negative Rate: 26.923076923076923
False Positive Rate: 22.857142857142858
------------------------------------------------------------------------------------------
