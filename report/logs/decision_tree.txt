Decision Tree

max_depth = 1
Train accuracy: 76.86%
Test accuracy: 72.13%

predictions= [0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0
 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0]

Number of mislabeled points out of a total 61 points : 17
The accuracy score achieved is: 72.13 %
Confusion Matrix: 
[[26  9]
 [ 8 18]]

Classification report on full data set:
              precision    recall  f1-score   support

           0       0.76      0.74      0.75        35
           1       0.67      0.69      0.68        26

    accuracy                           0.72        61
   macro avg       0.72      0.72      0.72        61
weighted avg       0.72      0.72      0.72        61

False Negative Rate: 30.76923076923077
False Positive Rate: 25.714285714285715
------------------------------------------------------------------------------------------

Seek optimal 'max_depth' parameter:

max_depth = 2
Train accuracy: 76.86%
Test accuracy: 72.13%

predictions= [0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0
 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0]

Number of mislabeled points out of a total 61 points : 17
The accuracy score achieved is: 72.13 %
Confusion Matrix: 
[[26  9]
 [ 8 18]]

Classification report on full data set:
              precision    recall  f1-score   support

           0       0.76      0.74      0.75        35
           1       0.67      0.69      0.68        26

    accuracy                           0.72        61
   macro avg       0.72      0.72      0.72        61
weighted avg       0.72      0.72      0.72        61

False Negative Rate: 30.76923076923077
False Positive Rate: 25.714285714285715
------------------------------------------------------------------------------------------
